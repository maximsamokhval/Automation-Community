
- [Собрать данные](#собрать-данные)
  - [Настройка технологического журнала на сбор данных](#настройка-технологического-журнала-на-сбор-данных)
    - [События для сбора](#события-для-сбора)
- [Получить имена таблиц](#получить-имена-таблиц)
- [Найти план запросов из кеша по тексту запросов](#найти-план-запросов-из-кеша-по-тексту-запросов)
- [Проверить актуальность статистики](#проверить-актуальность-статистики)
- [Получить граф взаимоблокировки](#получить-граф-взаимоблокировки)
- [Из Telegram чатов](#из-telegram-чатов)

## Собрать данные

### Настройка технологического журнала на сбор данных

#### События для сбора

**EXCP** - Для события EXCP достаточно установить только фильтр по имени базы, по этому событию мало пишется данных в технологический журнал.

**DBMSSQL** - Пишет очень много данных, поэтому здесь необходимо либо установить фильтры, либо разбирать огромный файл в поисках необходимой информации. Обязательно должны писаться все события DBMSSQL с отбором по свойству lkp=1 (необходимо для получения информации о жертве конфликта блокировок на уровне СУБД). Если же захочется найти источника блокировки, тогда, необходимо будет писать хотя бы все запросы с отбором по таблице на которой происходит конфликт.

Поскольку для анализа проблемы используется отдельная база, включить события EXCP и DBMSSQL с отбором по имени базы данных. ( свойство 
``` xml 
<like property="p:processName" value="MyDatabase%"/>
```
)

## Получить имена таблиц 

Использовать СтруктураХраненийБазыДанных() для определения объектов метаданных. 

## Найти план запросов из кеша по тексту запросов

[Способ получения плана запроса](../Методы%20получения%20плана%20запроса%20MSSQL.md)

## Проверить актуальность статистики

Сравнить ожидаемое и фактическое количество запрашиваемых и получаемых данных

## Получить граф взаимоблокировки

## Из Telegram чатов

[Источник](https://t.me/c/1238240640/658)

- Мертвая блокировка - это тоже блокировка, поэтому данная настройка и на него распространяется. Отличительная особенность - видишь ДЕДЛОКИ, взгляни на нагрузку CPU на стороне приложения - скорее всего увидишь прыжки до 100% на минуту-две-три.
- Хм. То есть придется разъяснить. Смотрите - до того как СУБД нашла ДЕДЛОК и кого-то из клиентов признала ЖЕРТВОЙ, происходят обычные блокировки - СУБД еще не успела ответить для текущая блокировка стала МЕРТВОЙ. Кстати - время на разруливание ДЕДЛОКА записывается в отдельное поле в MSSQL например.

Тут надо напомнить - про таймаут ожидания на блокировке. Это то время при котором будет происходить следующее (псевдокод примерный)

Пока НЕ ТАймАутНаБлокировке Цикл
     Успех = ПопытатьсяЗаблокироватьЗаписи();
     Если Не Успех Тогда Продолжить Иначе Прервать; КонецЕсли;
КонецЦикла 

Указанное поведение я еще называю ДОЛБЁЖКОЙ - выглядит обычно как нагрузка на CPU100%

Теперь смотрите что происходит 

1. Первая сессия приложение долбит СУБД с целью наложить блокировки - СУБД пока говорит НЕЛЬЗЯ, НО НЕ говорит НЕПОЛУЧИТЬСЯ
2. Вторая сессия приложение долбит СУБД с целью наложить блокировки - СУБД пока говорит НЕЛЬЗЯ, НО НЕ говорит НЕПОЛУЧИТЬСЯ
3. X сессия приложение долбит СУБД с целью наложить блокировки - СУБД пока говорит НЕЛЬЗЯ, НО НЕ говорит НЕПОЛУЧИТЬСЯ

В какой то момент - на нагруженных системах - это может быть ЦЕЛАЯ МИНУТА -  СУБД наконец-то сказало что мертво - и все сессии ОТВАЛИЛИСЬ по ошибке "Мертвые блокировки"

Но в эту минуту - вы увидите 100 нагрузку на CPU - что приводит обычно к жалобам пользователей приложение висит. Потому как в этом случае (нагрузка 100% CPU) жертвами уже становятся ВСЕ сессии на сервер приложений.